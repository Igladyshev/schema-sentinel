{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# MPM Test Data Loading with Snowpark\n",
    "\n",
    "This notebook loads MPM (Master Project Management) YAML files into a local Snowflake session using Snowpark.\n",
    "\n",
    "## Goals:\n",
    "1. Load 4 MPM YAML files (AZ, BS, CO, WY) with version 005\n",
    "2. Use Snowpark local testing session\n",
    "3. Create Snowpark DataFrames with schema variations\n",
    "4. Enable data comparison testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Ensure project root is in path for imports\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from snowflake.snowpark import Session as SnowparkSession\n",
    "from snowflake.snowpark.types import StructType, StructField, StringType, ArrayType, IntegerType\n",
    "\n",
    "# Import and reload to pick up schema changes\n",
    "from snowflake_local_testing import mpm_parser, mpm_snowpark, schema\n",
    "importlib.reload(schema)\n",
    "importlib.reload(mpm_parser)\n",
    "importlib.reload(mpm_snowpark)\n",
    "\n",
    "from snowflake_local_testing.mpm_parser import MPMConfig\n",
    "from snowflake_local_testing.mpm_snowpark import MPMSnowparkSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check environment\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd()\n",
    "print(f\"Current directory: {project_root}\")\n",
    "print(f\"\\nChecking if tests directory exists: {(project_root / 'tests').exists()}\")\n",
    "print(f\"Checking if tests/snowflake_local_testing exists: {(project_root / 'tests' / 'snowflake_local_testing').exists()}\")\n",
    "print(f\"Checking if mpm_parser.py exists: {(project_root / 'tests' / 'snowflake_local_testing' / 'mpm_parser.py').exists()}\")\n",
    "\n",
    "print(f\"\\nPython path:\")\n",
    "for p in sys.path[:5]:\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "# Try importing step by step\n",
    "try:\n",
    "    import tests\n",
    "    print(f\"\\n✓ tests module imported from: {tests.__file__}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Failed to import tests: {e}\")\n",
    "\n",
    "try:\n",
    "    import tests.snowflake_local_testing\n",
    "    print(f\"✓ tests.snowflake_local_testing imported\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to import tests.snowflake_local_testing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_DIR = Path.cwd()\n",
    "MPM_DIR = BASE_DIR / \"resources\" / \"master-mpm\"\n",
    "\n",
    "# MPM files to load\n",
    "MPM_FILES = {\n",
    "    \"AZ\": MPM_DIR / \"AZ\" / \"AZ_005-mpm.yaml\",\n",
    "    \"BS\": MPM_DIR / \"BS\" / \"BS_005-mpm.yaml\",\n",
    "    \"CO\": MPM_DIR / \"CO\" / \"CO_005-mpm.yaml\",\n",
    "    \"WY\": MPM_DIR / \"WY\" / \"WY_005-mpm.yaml\",\n",
    "}\n",
    "\n",
    "# Verify files exist\n",
    "print(\"Checking MPM files...\")\n",
    "for domain, mpm_file in MPM_FILES.items():\n",
    "    if not mpm_file.exists():\n",
    "        print(f\"⚠️  {domain}: File not found at {mpm_file}\")\n",
    "    else:\n",
    "        print(f\"✓ {domain}: {mpm_file.name} ({mpm_file.stat().st_size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local Snowpark session\n",
    "session = SnowparkSession.builder.configs({\n",
    "    \"local_testing\": True\n",
    "}).create()\n",
    "\n",
    "print(f\"✓ Snowpark session created (local testing mode)\")\n",
    "print(f\"Session ID: {session.session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse MPM configurations\n",
    "mpm_configs = {}\n",
    "\n",
    "for domain, mpm_file in MPM_FILES.items():\n",
    "    print(f\"\\nParsing {domain}...\")\n",
    "    config = MPMConfig(mpm_file)\n",
    "    mpm_configs[domain] = config\n",
    "\n",
    "    # Show summary\n",
    "    deployment = config.get_deployment_info()\n",
    "    communities = config.get_communities_list()\n",
    "    sensor_actions = config.get_sensor_actions()\n",
    "    report_actions = config.get_report_actions()\n",
    "\n",
    "    print(f\"  Deployment: {deployment.get('name', 'N/A')}\")\n",
    "    print(f\"  Communities: {len(communities)}\")\n",
    "    print(f\"  Sensor Actions: {len(sensor_actions)}\")\n",
    "    print(f\"  Report Actions: {len(report_actions)}\")\n",
    "\n",
    "print(f\"\\n✓ Parsed {len(mpm_configs)} MPM configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SQLite database connection\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy.orm import Session\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = BASE_DIR / \"resources\" / \"meta-db\" / \"schema-sentinel.db\"\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "engine = db.create_engine(f\"sqlite:///{DB_PATH}\")\n",
    "\n",
    "# Initialize MPM Snowpark Saver\n",
    "saver = MPMSnowparkSaver(session)\n",
    "print(f\"✓ MPMSnowparkSaver initialized\")\n",
    "print(f\"✓ SQLite database ready at {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all domains using Snowpark, then convert to pandas\n",
    "all_deployments = []\n",
    "all_communities = []\n",
    "all_sensor_actions = []\n",
    "all_report_actions = []\n",
    "\n",
    "for domain, config in mpm_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Loading {domain} domain...\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Create Snowpark DataFrames\n",
    "    deployment_sf_df = saver.save_deployment(\n",
    "        config.get_deployment_info(),\n",
    "        table_name=f\"{domain}_DEPLOYMENT\"\n",
    "    )\n",
    "\n",
    "    communities_sf_df = saver.save_communities(\n",
    "        config.get_communities_list(),\n",
    "        table_name=f\"{domain}_COMMUNITIES\"\n",
    "    )\n",
    "\n",
    "    sensor_actions_sf_df = saver.save_sensor_actions(\n",
    "        config.get_sensor_actions(),\n",
    "        table_name=f\"{domain}_SENSOR_ACTIONS\"\n",
    "    )\n",
    "\n",
    "    report_actions_sf_df = saver.save_report_actions(\n",
    "        config.get_report_actions(),\n",
    "        table_name=f\"{domain}_REPORT_ACTIONS\"\n",
    "    )\n",
    "\n",
    "    # Convert to pandas and collect\n",
    "    deployment_df = deployment_sf_df.to_pandas()\n",
    "    communities_df = communities_sf_df.to_pandas()\n",
    "    sensor_actions_df = sensor_actions_sf_df.to_pandas()\n",
    "    report_actions_df = report_actions_sf_df.to_pandas()\n",
    "\n",
    "    all_deployments.append(deployment_df)\n",
    "    all_communities.append(communities_df)\n",
    "    all_sensor_actions.append(sensor_actions_df)\n",
    "    all_report_actions.append(report_actions_df)\n",
    "\n",
    "    print(f\"✓ {domain} loaded:\")\n",
    "    print(f\"  - Deployment: {len(deployment_df)} rows\")\n",
    "    print(f\"  - Communities: {len(communities_df)} rows\")\n",
    "    print(f\"  - Sensor Actions: {len(sensor_actions_df)} rows\")\n",
    "    print(f\"  - Report Actions: {len(report_actions_df)} rows\")\n",
    "\n",
    "# Combine all domains into single DataFrames\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Combining all domains...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "deployments_df = pd.concat(all_deployments, ignore_index=True)\n",
    "communities_df = pd.concat(all_communities, ignore_index=True)\n",
    "sensor_actions_df = pd.concat(all_sensor_actions, ignore_index=True)\n",
    "report_actions_df = pd.concat(all_report_actions, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Combined DataFrames:\")\n",
    "print(f\"  - Total Deployments: {len(deployments_df)} rows\")\n",
    "print(f\"  - Total Communities: {len(communities_df)} rows\")\n",
    "print(f\"  - Total Sensor Actions: {len(sensor_actions_df)} rows\")\n",
    "print(f\"  - Total Report Actions: {len(report_actions_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary by domain\n",
    "print(\"\\nDeployments by domain:\")\n",
    "print(deployments_df.groupby('DOMAIN_CODE').size())\n",
    "\n",
    "print(\"\\nCommunities by domain:\")\n",
    "print(communities_df.groupby('DOMAIN_CODE').size())\n",
    "\n",
    "print(\"\\nSensor Actions by domain:\")\n",
    "print(sensor_actions_df.groupby('DOMAIN_CODE').size())\n",
    "\n",
    "print(\"\\nReport Actions by domain:\")\n",
    "print(report_actions_df.groupby('DOMAIN_CODE').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all DataFrames to SQLite using raw connection\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(str(DB_PATH))\n",
    "deployments_df.to_sql('mpm_deployments', conn, if_exists='replace', index=False)\n",
    "communities_df.to_sql('mpm_communities', conn, if_exists='replace', index=False)\n",
    "sensor_actions_df.to_sql('mpm_sensor_actions', conn, if_exists='replace', index=False)\n",
    "report_actions_df.to_sql('mpm_report_actions', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(f\"✓ Saved all domains to SQLite database: {DB_PATH}\")\n",
    "print(f\"  - mpm_deployments: {len(deployments_df)} rows\")\n",
    "print(f\"  - mpm_communities: {len(communities_df)} rows\")\n",
    "print(f\"  - mpm_sensor_actions: {len(sensor_actions_df)} rows\")\n",
    "print(f\"  - mpm_report_actions: {len(report_actions_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data in SQLite - show summary by domain\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(str(DB_PATH))\n",
    "\n",
    "print(\"Tables in database:\")\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "print(tables)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Deployments by domain:\")\n",
    "print(pd.read_sql_query(\"SELECT DOMAIN_CODE, COUNT(*) as count FROM mpm_deployments GROUP BY DOMAIN_CODE\", conn))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Communities by domain:\")\n",
    "print(pd.read_sql_query(\"SELECT DOMAIN_CODE, COUNT(*) as count FROM mpm_communities GROUP BY DOMAIN_CODE\", conn))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sensor Actions by domain:\")\n",
    "print(pd.read_sql_query(\"SELECT DOMAIN_CODE, COUNT(*) as count FROM mpm_sensor_actions GROUP BY DOMAIN_CODE\", conn))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Report Actions by domain:\")\n",
    "print(pd.read_sql_query(\"SELECT DOMAIN_CODE, COUNT(*) as count FROM mpm_report_actions GROUP BY DOMAIN_CODE\", conn))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample AZ communities:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM mpm_communities WHERE DOMAIN_CODE='AZ'\", conn))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample BS communities:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM mpm_communities WHERE DOMAIN_CODE='BS'\", conn))\n",
    "\n",
    "conn.close()\n",
    "print(f\"\\n✓ All 4 domains loaded successfully into {DB_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schema-sentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
