{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83c466d",
   "metadata": {},
   "source": [
    "# MPM Comparison and Migration\n",
    "\n",
    "This notebook provides tools to:\n",
    "1. Compare MPM deployments to find common and unique report actions\n",
    "2. Migrate (copy) report actions between deployments with proper attribute adjustments\n",
    "\n",
    "## Key Considerations:\n",
    "- Deployment-specific attributes: `domain_code`, `deployment_version`, `deployment_code` (schema name)\n",
    "- Communities lists need adjustment for target deployment\n",
    "- Schedules differ between domains\n",
    "- Parent dependencies need validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13609458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: /Users/igor.gladyshev/PycharmProjects/schema-sentinel/resources/meta-db/schema-sentinel.db\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Setup paths\n",
    "BASE_DIR = Path.cwd()\n",
    "DB_PATH = BASE_DIR / \"resources\" / \"meta-db\" / \"schema-sentinel.db\"\n",
    "\n",
    "print(f\"Database: {DB_PATH}\")\n",
    "print(f\"Exists: {DB_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5e6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "  Deployments: 4 rows\n",
      "  Communities: 10 rows\n",
      "  Sensor Actions: 71 rows\n",
      "  Report Actions: 320 rows\n",
      "\n",
      "Available domains:\n",
      "DOMAIN_CODE DEPLOYMENT_VERSION\n",
      "         AZ              0.0.5\n",
      "         BS              0.0.5\n",
      "         CO              0.0.5\n",
      "         WY              0.0.5\n"
     ]
    }
   ],
   "source": [
    "# Load all data from SQLite\n",
    "conn = sqlite3.connect(str(DB_PATH))\n",
    "\n",
    "deployments_df = pd.read_sql_query(\"SELECT * FROM mpm_deployments\", conn)\n",
    "communities_df = pd.read_sql_query(\"SELECT * FROM mpm_communities\", conn)\n",
    "sensor_actions_df = pd.read_sql_query(\"SELECT * FROM mpm_sensor_actions\", conn)\n",
    "report_actions_df = pd.read_sql_query(\"SELECT * FROM mpm_report_actions\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"Data loaded:\")\n",
    "print(f\"  Deployments: {len(deployments_df)} rows\")\n",
    "print(f\"  Communities: {len(communities_df)} rows\")\n",
    "print(f\"  Sensor Actions: {len(sensor_actions_df)} rows\")\n",
    "print(f\"  Report Actions: {len(report_actions_df)} rows\")\n",
    "\n",
    "print(\"\\nAvailable domains:\")\n",
    "print(deployments_df[['DOMAIN_CODE', 'DEPLOYMENT_VERSION']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b33c67",
   "metadata": {},
   "source": [
    "## 1. Compare Report Actions Between Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b09eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Comparison: AZ vs BS\n",
      "================================================================================\n",
      "Common report actions: 58\n",
      "Only in AZ: 52\n",
      "Only in BS: 3\n",
      "\n",
      "Common actions:\n",
      "  - retail_liability_ticket_report\n",
      "  - retail_liability_ticket_report_per_community\n",
      "  - retail_recap_all_report\n",
      "  - retail_recap_all_report_month_to_date\n",
      "  - retail_recap_report_per_community\n",
      "  - retail_sports_pool_cancelled_ticket_report\n",
      "  - retail_sports_pool_cancelled_ticket_report_month_to_date\n",
      "  - retail_sports_pool_cancelled_ticket_report_month_to_date_per_community\n",
      "  - retail_sports_pool_cancelled_ticket_report_per_community\n",
      "  - retail_sports_pool_expired_ticket_report\n",
      "  ... and 48 more\n",
      "\n",
      "Only in AZ (sample):\n",
      "  - 3k_report_bop\n",
      "  - bop_cash_deposit_withdrawal_transaction_report\n",
      "  - daily_transaction_deposit_withdrawal_report_bop\n",
      "  - daily_transaction_report_bop\n",
      "  - dormant_acct_report_bop\n",
      "  - dtr_deposit_failed_backin_report\n",
      "  - forfeited_bonus_winnings_report_bop\n",
      "  - liability_ticket_report_bop\n",
      "  - month_to_date_transaction_deposit_withdrawal_report_bop\n",
      "  - noncashable_bonus_balance_report_bop\n",
      "  ... and 42 more\n",
      "\n",
      "Only in BS (sample):\n",
      "  - retail_recap_report_month_to_date_per_community\n",
      "  - taxable_handle_recap_vs_trans_month_to_date_report\n",
      "  - taxable_handle_recap_vs_trans_report\n"
     ]
    }
   ],
   "source": [
    "def compare_report_actions(domain1: str, domain2: str, df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare report actions between two domains.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - common: action_codes in both domains\n",
    "        - only_in_domain1: action_codes only in domain1\n",
    "        - only_in_domain2: action_codes only in domain2\n",
    "        - common_details: DataFrame with side-by-side comparison\n",
    "    \"\"\"\n",
    "    df1 = df[df['DOMAIN_CODE'] == domain1].copy()\n",
    "    df2 = df[df['DOMAIN_CODE'] == domain2].copy()\n",
    "\n",
    "    actions1 = set(df1['ACTION_CODE'].unique())\n",
    "    actions2 = set(df2['ACTION_CODE'].unique())\n",
    "\n",
    "    common = actions1 & actions2\n",
    "    only_in_1 = actions1 - actions2\n",
    "    only_in_2 = actions2 - actions1\n",
    "\n",
    "    # Create side-by-side comparison for common actions\n",
    "    common_details = []\n",
    "    for action_code in sorted(common):\n",
    "        row1 = df1[df1['ACTION_CODE'] == action_code].iloc[0]\n",
    "        row2 = df2[df2['ACTION_CODE'] == action_code].iloc[0]\n",
    "\n",
    "        common_details.append({\n",
    "            'ACTION_CODE': action_code,\n",
    "            f'{domain1}_REPORT_NAME': row1['REPORT_NAME'],\n",
    "            f'{domain2}_REPORT_NAME': row2['REPORT_NAME'],\n",
    "            f'{domain1}_COMMUNITIES': row1['COMMUNITIES'],\n",
    "            f'{domain2}_COMMUNITIES': row2['COMMUNITIES'],\n",
    "            f'{domain1}_SCHEDULE': row1['SCHEDULE'],\n",
    "            f'{domain2}_SCHEDULE': row2['SCHEDULE'],\n",
    "            'NAMES_MATCH': row1['REPORT_NAME'] == row2['REPORT_NAME'],\n",
    "            'SCHEDULES_MATCH': row1['SCHEDULE'] == row2['SCHEDULE'],\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'common': sorted(common),\n",
    "        'only_in_domain1': sorted(only_in_1),\n",
    "        'only_in_domain2': sorted(only_in_2),\n",
    "        'common_details': pd.DataFrame(common_details),\n",
    "        'count_common': len(common),\n",
    "        'count_only_domain1': len(only_in_1),\n",
    "        'count_only_domain2': len(only_in_2),\n",
    "    }\n",
    "\n",
    "# Example: Compare AZ and BS\n",
    "comparison = compare_report_actions('AZ', 'BS', report_actions_df)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Comparison: AZ vs BS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Common report actions: {comparison['count_common']}\")\n",
    "print(f\"Only in AZ: {comparison['count_only_domain1']}\")\n",
    "print(f\"Only in BS: {comparison['count_only_domain2']}\")\n",
    "\n",
    "print(f\"\\nCommon actions:\")\n",
    "for action in comparison['common'][:10]:  # Show first 10\n",
    "    print(f\"  - {action}\")\n",
    "if len(comparison['common']) > 10:\n",
    "    print(f\"  ... and {len(comparison['common']) - 10} more\")\n",
    "\n",
    "print(f\"\\nOnly in AZ (sample):\")\n",
    "for action in comparison['only_in_domain1'][:10]:\n",
    "    print(f\"  - {action}\")\n",
    "if len(comparison['only_in_domain1']) > 10:\n",
    "    print(f\"  ... and {len(comparison['only_in_domain1']) - 10} more\")\n",
    "\n",
    "print(f\"\\nOnly in BS (sample):\")\n",
    "for action in comparison['only_in_domain2'][:10]:\n",
    "    print(f\"  - {action}\")\n",
    "if len(comparison['only_in_domain2']) > 10:\n",
    "    print(f\"  ... and {len(comparison['only_in_domain2']) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a51df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common actions - detailed comparison:\n",
      "\n",
      "Actions with different names:\n",
      "                                             ACTION_CODE                                AZ_REPORT_NAME                                           BS_REPORT_NAME\n",
      "            retail_liability_ticket_report_per_community    Retail Sports Pool Liability Ticket Report Retail Sports Pool Liability Ticket Report Per Community\n",
      "                   retail_recap_all_report_month_to_date Retail Sports Pool Recap Report Month To Date            Retail Sports Pool Recap Month To Date Report\n",
      "                       retail_recap_report_per_community                           Retail Recap Report            Retail Sports Pool Recap Report Per Community\n",
      "retail_sports_pool_cancelled_ticket_report_per_community           Retail Sports Pool Cancelled Report        Retail Sports Pool Cancelled Report Per Community\n",
      "    retail_sports_pool_resettlement_report_per_community        Retail Sports Pool Resettlement Report     Retail Sports Pool Resettlement Report Per Community\n",
      "   retail_sports_pool_voided_ticket_report_per_community              Retail Sports Pool Voided Report           Retail Sports Pool Voided Report Per Community\n",
      "                        rosi_big_transactions_report_all              Rosi Big Transactions Report All                             Rosi Big Transactions Report\n",
      "              rosi_big_transactions_report_per_community                  Rosi Big Transactions Report               Rosi Big Transactions Report Per Community\n",
      "                             rosi_bill_denominations_all            Rosi Bill Denominations Report All                           Rosi Bill Denominations Report\n",
      "                   rosi_bill_denominations_per_community                Rosi Bill Denominations Report             Rosi Bill Denominations Report Per Community\n",
      "                                  rosi_cash_balances_all                 Rosi Cash Balances Report All                                Rosi Cash Balances Report\n",
      "                        rosi_cash_balances_per_community                     Rosi Cash Balances Report                  Rosi Cash Balances Report Per Community\n",
      "                      rosi_daily_transactions_report_all            Rosi Daily Transactions Report All                           Rosi Daily Transactions Report\n",
      "            rosi_daily_transactions_report_per_community                Rosi Daily Transactions Report             Rosi Daily Transactions Report Per Community\n",
      "                   rosi_electronic_accounting_report_all         Rosi Electronic Accounting Report All                        Rosi Electronic Accounting Report\n",
      "         rosi_electronic_accounting_report_per_community             Rosi Electronic Accounting Report          Rosi Electronic Accounting Report Per Community\n",
      "                            rosi_irs_paids_per_community                         Rosi Irs Paids Report                      Rosi IRS Paids Report Per Community\n",
      "         rosi_patron_kiosk_activity_report_per_community             Rosi Patron Kiosk Activity Report          Rosi Patron Kiosk Activity Report Per Community\n",
      "                  rosi_teller_balance_by_cage_report_all        Rosi Teller Balance By Cage Report All                       Rosi Teller Balance By Cage Report\n",
      "        rosi_teller_balance_by_cage_report_per_community            Rosi Teller Balance By Cage Report         Rosi Teller Balance by Cage Report Per Community\n",
      "                 rosi_teller_balance_by_kiosk_report_all       Rosi Teller Balance By Kiosk Report All                      Rosi Teller Balance By Kiosk Report\n",
      "       rosi_teller_balance_by_kiosk_report_per_community           Rosi Teller Balance By Kiosk Report        Rosi Teller Balance By Kiosk Report Per Community\n",
      "                          rosi_teller_balance_report_all                Rosi Teller Balance Report All                               Rosi Teller Balance Report\n",
      "                rosi_teller_balance_report_per_community                    Rosi Teller Balance Report                 Rosi Teller Balance Report Per Community\n",
      "                                 rosi_voucher_weekly_all                Rosi Voucher Weekly Report All                               Rosi Voucher Weekly Report\n",
      "                       rosi_voucher_weekly_per_community                    Rosi Voucher Weekly Report                 Rosi Voucher Weekly Report Per Community\n",
      "                               rosi_vouchers_created_all                   Vouchers Created Report All                             Rosi Vouchers Created Report\n",
      "                     rosi_vouchers_created_per_community                       Vouchers Created Report               Rosi Vouchers Created Report Per Community\n",
      "                               rosi_vouchers_expired_all                   Vouchers Expired Report All                             Rosi Vouchers Expired Report\n",
      "                     rosi_vouchers_expired_per_community                       Vouchers Expired Report               Rosi Vouchers Expired Report Per Community\n",
      "                               rosi_vouchers_paidout_all                   Vouchers Paidout Report All                             Rosi Vouchers PaidOut Report\n",
      "                     rosi_vouchers_paidout_per_community                       Vouchers Paidout Report               Rosi Vouchers PaidOut Report Per Community\n",
      "                                rosi_vouchers_unpaid_all                    Vouchers Unpaid Report All                              Rosi Vouchers Unpaid Report\n",
      "                      rosi_vouchers_unpaid_per_community                        Vouchers Unpaid Report                Rosi Vouchers Unpaid Report Per Community\n",
      "\n",
      "Actions with different schedules:\n",
      "Count: 58\n",
      "                                 ACTION_CODE                                                AZ_SCHEDULE                                                BS_SCHEDULE\n",
      "              retail_liability_ticket_report  {\\n  \"crontab\": \"5 17 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n} {\\n  \"crontab\": \"15 13 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n}\n",
      "retail_liability_ticket_report_per_community  {\\n  \"crontab\": \"5 17 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n} {\\n  \"crontab\": \"15 13 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n}\n",
      "                     retail_recap_all_report  {\\n  \"crontab\": \"5 17 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n} {\\n  \"crontab\": \"15 13 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n}\n",
      "       retail_recap_all_report_month_to_date {\\n  \"crontab\": \"35 17 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n} {\\n  \"crontab\": \"15 13 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n}\n",
      "           retail_recap_report_per_community  {\\n  \"crontab\": \"5 17 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n} {\\n  \"crontab\": \"15 13 * * *\",\\n  \"timezone\": \"Etc/UTC\"\\n}\n"
     ]
    }
   ],
   "source": [
    "# View detailed comparison for common actions\n",
    "print(\"Common actions - detailed comparison:\")\n",
    "print(\"\\nActions with different names:\")\n",
    "diff_names = comparison['common_details'][~comparison['common_details']['NAMES_MATCH']]\n",
    "print(diff_names[['ACTION_CODE', 'AZ_REPORT_NAME', 'BS_REPORT_NAME']].to_string(index=False))\n",
    "\n",
    "print(\"\\nActions with different schedules:\")\n",
    "diff_schedules = comparison['common_details'][~comparison['common_details']['SCHEDULES_MATCH']]\n",
    "print(f\"Count: {len(diff_schedules)}\")\n",
    "if len(diff_schedules) > 0:\n",
    "    print(diff_schedules[['ACTION_CODE', 'AZ_SCHEDULE', 'BS_SCHEDULE']].head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc69c4a",
   "metadata": {},
   "source": [
    "## 2. Comparison Matrix - All Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cd6526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Actions Comparison Matrix:\n",
      "================================================================================\n",
      "Domain          AZ         BS          CO         WY\n",
      "    AZ 110 (total)  58 common  101 common  40 common\n",
      "    BS   58 common 61 (total)   58 common   0 common\n",
      "    CO  101 common  58 common 107 (total)  40 common\n",
      "    WY   40 common   0 common   40 common 42 (total)\n"
     ]
    }
   ],
   "source": [
    "# Create comparison matrix for all domain pairs\n",
    "domains = deployments_df['DOMAIN_CODE'].unique()\n",
    "\n",
    "print(\"Report Actions Comparison Matrix:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "matrix = []\n",
    "for d1 in domains:\n",
    "    row = {'Domain': d1}\n",
    "    for d2 in domains:\n",
    "        if d1 == d2:\n",
    "            total = len(report_actions_df[report_actions_df['DOMAIN_CODE'] == d1])\n",
    "            row[d2] = f\"{total} (total)\"\n",
    "        else:\n",
    "            comp = compare_report_actions(d1, d2, report_actions_df)\n",
    "            row[d2] = f\"{comp['count_common']} common\"\n",
    "    matrix.append(row)\n",
    "\n",
    "matrix_df = pd.DataFrame(matrix)\n",
    "print(matrix_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac1768",
   "metadata": {},
   "source": [
    "## 3. Migration Helper - Copy Report Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951937bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migration helper functions loaded.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class MigrationConfig:\n",
    "    \"\"\"Configuration for migrating a report action between domains.\"\"\"\n",
    "    source_domain: str\n",
    "    target_domain: str\n",
    "    action_code: str\n",
    "    # Optional overrides\n",
    "    new_schedule: str = None\n",
    "    new_communities: List[str] = None\n",
    "    adjust_parents: bool = True\n",
    "\n",
    "def prepare_action_migration(\n",
    "    config: MigrationConfig,\n",
    "    report_actions_df: pd.DataFrame,\n",
    "    deployments_df: pd.DataFrame,\n",
    "    communities_df: pd.DataFrame\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Prepare a report action for migration from source to target domain.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - original: Original action data\n",
    "        - migrated: Adjusted action data for target domain\n",
    "        - changes: List of changes made\n",
    "        - warnings: List of warnings/issues to address\n",
    "    \"\"\"\n",
    "    # Get source action\n",
    "    source_action = report_actions_df[\n",
    "        (report_actions_df['DOMAIN_CODE'] == config.source_domain) &\n",
    "        (report_actions_df['ACTION_CODE'] == config.action_code)\n",
    "    ]\n",
    "\n",
    "    if len(source_action) == 0:\n",
    "        raise ValueError(f\"Action {config.action_code} not found in {config.source_domain}\")\n",
    "\n",
    "    source_action = source_action.iloc[0].to_dict()\n",
    "\n",
    "    # Get target deployment info\n",
    "    target_deployment = deployments_df[\n",
    "        deployments_df['DOMAIN_CODE'] == config.target_domain\n",
    "    ].iloc[0]\n",
    "\n",
    "    # Get target communities\n",
    "    target_communities = communities_df[\n",
    "        communities_df['DOMAIN_CODE'] == config.target_domain\n",
    "    ]['COMMUNITY_ID'].tolist()\n",
    "\n",
    "    # Create migrated action\n",
    "    migrated = source_action.copy()\n",
    "    changes = []\n",
    "    warnings = []\n",
    "\n",
    "    # 1. Update deployment-specific attributes\n",
    "    migrated['DOMAIN_CODE'] = config.target_domain\n",
    "    changes.append(f\"DOMAIN_CODE: {source_action['DOMAIN_CODE']} → {config.target_domain}\")\n",
    "\n",
    "    migrated['DEPLOYMENT_VERSION'] = target_deployment['DEPLOYMENT_VERSION']\n",
    "    changes.append(f\"DEPLOYMENT_VERSION: {source_action['DEPLOYMENT_VERSION']} → {target_deployment['DEPLOYMENT_VERSION']}\")\n",
    "\n",
    "    # 2. Adjust communities\n",
    "    try:\n",
    "        communities = json.loads(source_action['COMMUNITIES']) if source_action['COMMUNITIES'] else []\n",
    "\n",
    "        if config.new_communities is not None:\n",
    "            # Use specified communities\n",
    "            new_communities = config.new_communities\n",
    "            changes.append(f\"COMMUNITIES: {len(communities)} → {len(new_communities)} (manually specified)\")\n",
    "        elif communities:\n",
    "            # Check if source communities exist in target\n",
    "            valid_communities = [c for c in communities if c in target_communities]\n",
    "            invalid_communities = [c for c in communities if c not in target_communities]\n",
    "\n",
    "            if invalid_communities:\n",
    "                warnings.append(f\"Communities not in target: {invalid_communities}\")\n",
    "                warnings.append(f\"Valid target communities: {target_communities}\")\n",
    "\n",
    "            new_communities = valid_communities\n",
    "            changes.append(f\"COMMUNITIES: {len(communities)} → {len(valid_communities)} (filtered for target)\")\n",
    "        else:\n",
    "            new_communities = []\n",
    "\n",
    "        migrated['COMMUNITIES'] = json.dumps(new_communities)\n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        warnings.append(f\"Failed to parse COMMUNITIES: {e}\")\n",
    "\n",
    "    # 3. Adjust schedule\n",
    "    if config.new_schedule:\n",
    "        migrated['SCHEDULE'] = config.new_schedule\n",
    "        changes.append(f\"SCHEDULE: Updated with provided schedule\")\n",
    "    else:\n",
    "        warnings.append(\"SCHEDULE: Review required - may need timezone/timing adjustments\")\n",
    "\n",
    "    # 4. Check parents\n",
    "    try:\n",
    "        parents = json.loads(source_action['PARENTS']) if source_action['PARENTS'] else []\n",
    "        if parents:\n",
    "            # Check if parents exist in target domain\n",
    "            target_actions = set(report_actions_df[\n",
    "                report_actions_df['DOMAIN_CODE'] == config.target_domain\n",
    "            ]['ACTION_CODE'].tolist())\n",
    "\n",
    "            missing_parents = [p for p in parents if p not in target_actions]\n",
    "            if missing_parents:\n",
    "                warnings.append(f\"Parent actions not in target: {missing_parents}\")\n",
    "                if config.adjust_parents:\n",
    "                    valid_parents = [p for p in parents if p in target_actions]\n",
    "                    migrated['PARENTS'] = json.dumps(valid_parents)\n",
    "                    changes.append(f\"PARENTS: Removed missing parents - {len(parents)} → {len(valid_parents)}\")\n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        warnings.append(f\"Failed to parse PARENTS: {e}\")\n",
    "\n",
    "    # 5. Update query reference schema names\n",
    "    try:\n",
    "        query_ref = json.loads(source_action['QUERY_REFERENCE']) if source_action['QUERY_REFERENCE'] else {}\n",
    "        if query_ref and 'database_name' in query_ref:\n",
    "            # This might need schema name adjustment\n",
    "            warnings.append(f\"QUERY_REFERENCE: Review database_name '{query_ref['database_name']}' - may need schema adjustment\")\n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        warnings.append(f\"Failed to parse QUERY_REFERENCE: {e}\")\n",
    "\n",
    "    return {\n",
    "        'original': source_action,\n",
    "        'migrated': migrated,\n",
    "        'changes': changes,\n",
    "        'warnings': warnings,\n",
    "    }\n",
    "\n",
    "print(\"Migration helper functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83717fbb",
   "metadata": {},
   "source": [
    "## 4. Example: Prepare Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded81b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Migrating action 'rosi_bill_denominations_per_community' from AZ to WY\n",
      "\n",
      "Changes to be made:\n",
      "  ✓ DOMAIN_CODE: AZ → WY\n",
      "  ✓ DEPLOYMENT_VERSION: 0.0.5 → 0.0.5\n",
      "  ✓ COMMUNITIES: 3 → 0 (filtered for target)\n",
      "  ✓ PARENTS: Removed missing parents - 1 → 0\n",
      "\n",
      "Warnings - Manual Review Required:\n",
      "  ⚠️  Communities not in target: ['Chase_Field', 'Harrahs_Ak_Chin', 'Arizona_Downs']\n",
      "  ⚠️  Valid target communities: []\n",
      "  ⚠️  SCHEDULE: Review required - may need timezone/timing adjustments\n",
      "  ⚠️  Parent actions not in target: ['rosi_bill_denominations_all']\n",
      "  ⚠️  QUERY_REFERENCE: Review database_name 'NJ_Prod' - may need schema adjustment\n",
      "\n",
      "Original action details:\n",
      "  ACTION_CODE: rosi_bill_denominations_per_community\n",
      "  REPORT_NAME: Rosi Bill Denominations Report\n",
      "  DOMAIN_CODE: AZ\n",
      "  COMMUNITIES: [\n",
      "  \"Chase_Field\",\n",
      "  \"Harrahs_Ak_Chin\",\n",
      "  \"Arizona_Downs\"\n",
      "]\n",
      "\n",
      "Migrated action details:\n",
      "  ACTION_CODE: rosi_bill_denominations_per_community\n",
      "  REPORT_NAME: Rosi Bill Denominations Report\n",
      "  DOMAIN_CODE: WY\n",
      "  COMMUNITIES: []\n"
     ]
    }
   ],
   "source": [
    "# Example: Migrate a report action from AZ to WY\n",
    "# First, find a common action to use as example\n",
    "az_actions = set(report_actions_df[report_actions_df['DOMAIN_CODE'] == 'AZ']['ACTION_CODE'])\n",
    "example_action = list(az_actions)[0] if az_actions else None\n",
    "\n",
    "if example_action:\n",
    "    print(f\"Example: Migrating action '{example_action}' from AZ to WY\\n\")\n",
    "\n",
    "    config = MigrationConfig(\n",
    "        source_domain='AZ',\n",
    "        target_domain='WY',\n",
    "        action_code=example_action,\n",
    "        adjust_parents=True\n",
    "    )\n",
    "\n",
    "    result = prepare_action_migration(\n",
    "        config,\n",
    "        report_actions_df,\n",
    "        deployments_df,\n",
    "        communities_df\n",
    "    )\n",
    "\n",
    "    print(\"Changes to be made:\")\n",
    "    for change in result['changes']:\n",
    "        print(f\"  ✓ {change}\")\n",
    "\n",
    "    if result['warnings']:\n",
    "        print(\"\\nWarnings - Manual Review Required:\")\n",
    "        for warning in result['warnings']:\n",
    "            print(f\"  ⚠️  {warning}\")\n",
    "\n",
    "    print(\"\\nOriginal action details:\")\n",
    "    print(f\"  ACTION_CODE: {result['original']['ACTION_CODE']}\")\n",
    "    print(f\"  REPORT_NAME: {result['original']['REPORT_NAME']}\")\n",
    "    print(f\"  DOMAIN_CODE: {result['original']['DOMAIN_CODE']}\")\n",
    "    print(f\"  COMMUNITIES: {result['original']['COMMUNITIES']}\")\n",
    "\n",
    "    print(\"\\nMigrated action details:\")\n",
    "    print(f\"  ACTION_CODE: {result['migrated']['ACTION_CODE']}\")\n",
    "    print(f\"  REPORT_NAME: {result['migrated']['REPORT_NAME']}\")\n",
    "    print(f\"  DOMAIN_CODE: {result['migrated']['DOMAIN_CODE']}\")\n",
    "    print(f\"  COMMUNITIES: {result['migrated']['COMMUNITIES']}\")\n",
    "else:\n",
    "    print(\"No actions found to use as example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e8d2c",
   "metadata": {},
   "source": [
    "## 5. Batch Analysis - Actions to Consider Migrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf7032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions in AZ that could be migrated to WY: 70\n",
      "\n",
      "Sample candidates:\n",
      "                                                           ACTION_CODE                                                                    REPORT_NAME ABBREVIATION ACTION_TYPE SOURCE TARGET\n",
      "                                                         3k_report_bop                                    Deposit Withdrawal {retail_property} Report          KRB      REPORT     AZ     WY\n",
      "                        bop_cash_deposit_withdrawal_transaction_report                                     Cash Deposit Withdrawal Transaction Report       BCDWTR      REPORT     AZ     WY\n",
      "                    noncashable_bonus_balance_report_bop_month_to_date                                Non-cashable Bonus Balance Month To Date Report     NBBRBMTD      REPORT     AZ     WY\n",
      "                                            parlay_card_trading_report                                                     Parlay Card Trading Report         PCTR      REPORT     AZ     WY\n",
      "                                        retail_liability_ticket_report                                     Retail Sports Pool Liability Ticket Report         RLTR      REPORT     AZ     WY\n",
      "                          retail_liability_ticket_report_per_community                                     Retail Sports Pool Liability Ticket Report       RLTRPC      REPORT     AZ     WY\n",
      "                                               retail_recap_all_report                                                Retail Sports Pool Recap Report         RRAR      REPORT     AZ     WY\n",
      "                                 retail_recap_all_report_month_to_date                                  Retail Sports Pool Recap Report Month To Date      RRARMTD      REPORT     AZ     WY\n",
      "                                  retail_recap_all_report_year_to_date                                   Retail Sports Pool Recap Report Year To Date      RRARYTD      REPORT     AZ     WY\n",
      "                                     retail_recap_report_month_to_date                                  Retail Sports Pool Recap Report Month To Date       RRRMTD      REPORT     AZ     WY\n",
      "                        retail_recap_report_per_community_year_to_date                     Retail Sports Pool Recap Report Per Community Year To Date     RRRPCYTD      REPORT     AZ     WY\n",
      "                                     retail_recap_report_per_community                                                            Retail Recap Report        RRRPC      REPORT     AZ     WY\n",
      "                            retail_sports_pool_cancelled_ticket_report                                            Retail Sports Pool Cancelled Report       RSPCTR      REPORT     AZ     WY\n",
      "              retail_sports_pool_cancelled_ticket_report_per_community                                            Retail Sports Pool Cancelled Report     RSPCTRPC      REPORT     AZ     WY\n",
      "                              retail_sports_pool_expired_ticket_report                                              Retail Sports Pool Expired Report       RSPETR      REPORT     AZ     WY\n",
      "                retail_sports_pool_expired_ticket_report_per_community                                Retail Sports Pool Expired Report Per Community     RSPETRPC      REPORT     AZ     WY\n",
      "              retail_sports_pool_pending_voidscancels_lifetime_to_date               Retail Sports Pool Pending Voids/cancels Lifetime To Date Report     RSPPVLTD      REPORT     AZ     WY\n",
      "retail_sports_pool_pending_voidscancels_lifetime_to_date_per_community Retail Sports Pool Pending Voids/cancels Lifetime To Date Report Per Community   RSPPVLTDPC      REPORT     AZ     WY\n",
      "                        retail_sports_pool_pending_voidscancels_report                                Retail Sports Pool Pending Voids/cancels Report       RSPPVR      REPORT     AZ     WY\n",
      "          retail_sports_pool_pending_voidscancels_report_per_community                  Retail Sports Pool Pending Voids/cancels Report Per Community     RSPPVRPC      REPORT     AZ     WY\n"
     ]
    }
   ],
   "source": [
    "def analyze_migration_candidates(\n",
    "    source_domain: str,\n",
    "    target_domain: str,\n",
    "    report_actions_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze which actions from source could be migrated to target.\n",
    "    \"\"\"\n",
    "    comparison = compare_report_actions(source_domain, target_domain, report_actions_df)\n",
    "\n",
    "    # Actions only in source are candidates\n",
    "    candidates = report_actions_df[\n",
    "        (report_actions_df['DOMAIN_CODE'] == source_domain) &\n",
    "        (report_actions_df['ACTION_CODE'].isin(comparison['only_in_domain1']))\n",
    "    ][['ACTION_CODE', 'REPORT_NAME', 'ABBREVIATION', 'ACTION_TYPE']].copy()\n",
    "\n",
    "    candidates['SOURCE'] = source_domain\n",
    "    candidates['TARGET'] = target_domain\n",
    "\n",
    "    return candidates\n",
    "\n",
    "# Example: What could we migrate from AZ to WY?\n",
    "candidates = analyze_migration_candidates('AZ', 'WY', report_actions_df)\n",
    "\n",
    "print(f\"\\nActions in AZ that could be migrated to WY: {len(candidates)}\")\n",
    "print(\"\\nSample candidates:\")\n",
    "print(candidates.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6511239",
   "metadata": {},
   "source": [
    "## 6. Export Migration Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f43c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Migration Plan Summary:\n",
      "                                       ACTION_CODE                                     REPORT_NAME          STATUS  WARNINGS_COUNT\n",
      "                                     3k_report_bop     Deposit Withdrawal {retail_property} Report REVIEW_REQUIRED               5\n",
      "    bop_cash_deposit_withdrawal_transaction_report      Cash Deposit Withdrawal Transaction Report REVIEW_REQUIRED               3\n",
      "noncashable_bonus_balance_report_bop_month_to_date Non-cashable Bonus Balance Month To Date Report REVIEW_REQUIRED               2\n",
      "                        parlay_card_trading_report                      Parlay Card Trading Report REVIEW_REQUIRED               3\n",
      "                    retail_liability_ticket_report      Retail Sports Pool Liability Ticket Report REVIEW_REQUIRED               3\n",
      "\n",
      "Full migration plan saved to: /Users/igor.gladyshev/PycharmProjects/schema-sentinel/migration_plan_AZ_to_WY.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a migration plan for review\n",
    "def create_migration_plan(\n",
    "    source_domain: str,\n",
    "    target_domain: str,\n",
    "    action_codes: List[str],\n",
    "    report_actions_df: pd.DataFrame,\n",
    "    deployments_df: pd.DataFrame,\n",
    "    communities_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a migration plan for multiple actions.\n",
    "    \"\"\"\n",
    "    plan = []\n",
    "\n",
    "    for action_code in action_codes:\n",
    "        try:\n",
    "            config = MigrationConfig(\n",
    "                source_domain=source_domain,\n",
    "                target_domain=target_domain,\n",
    "                action_code=action_code,\n",
    "                adjust_parents=True\n",
    "            )\n",
    "\n",
    "            result = prepare_action_migration(\n",
    "                config,\n",
    "                report_actions_df,\n",
    "                deployments_df,\n",
    "                communities_df\n",
    "            )\n",
    "\n",
    "            plan.append({\n",
    "                'ACTION_CODE': action_code,\n",
    "                'REPORT_NAME': result['original']['REPORT_NAME'],\n",
    "                'SOURCE': source_domain,\n",
    "                'TARGET': target_domain,\n",
    "                'CHANGES_COUNT': len(result['changes']),\n",
    "                'WARNINGS_COUNT': len(result['warnings']),\n",
    "                'STATUS': 'READY' if len(result['warnings']) == 0 else 'REVIEW_REQUIRED',\n",
    "                'WARNINGS': ' | '.join(result['warnings']) if result['warnings'] else '',\n",
    "            })\n",
    "        except Exception as e:\n",
    "            plan.append({\n",
    "                'ACTION_CODE': action_code,\n",
    "                'REPORT_NAME': '',\n",
    "                'SOURCE': source_domain,\n",
    "                'TARGET': target_domain,\n",
    "                'CHANGES_COUNT': 0,\n",
    "                'WARNINGS_COUNT': 1,\n",
    "                'STATUS': 'ERROR',\n",
    "                'WARNINGS': str(e),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(plan)\n",
    "\n",
    "# Example: Create migration plan for first 5 candidates\n",
    "sample_actions = candidates['ACTION_CODE'].head(5).tolist()\n",
    "\n",
    "if sample_actions:\n",
    "    migration_plan = create_migration_plan(\n",
    "        'AZ', 'WY',\n",
    "        sample_actions,\n",
    "        report_actions_df,\n",
    "        deployments_df,\n",
    "        communities_df\n",
    "    )\n",
    "\n",
    "    print(\"\\nMigration Plan Summary:\")\n",
    "    print(migration_plan[['ACTION_CODE', 'REPORT_NAME', 'STATUS', 'WARNINGS_COUNT']].to_string(index=False))\n",
    "\n",
    "    # Save to CSV for review\n",
    "    output_path = BASE_DIR / \"migration_plan_AZ_to_WY.csv\"\n",
    "    migration_plan.to_csv(output_path, index=False)\n",
    "    print(f\"\\nFull migration plan saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06f804",
   "metadata": {},
   "source": [
    "## 7. Generic Table Comparison Framework\n",
    "\n",
    "Using YAML Shredder output or any table structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class TableConfig:\n",
    "    \"\"\"Configuration for a table to compare.\"\"\"\n",
    "    name: str\n",
    "    primary_key: str\n",
    "    grouping_column: str  # e.g., DOMAIN_CODE\n",
    "    display_columns: List[str]  # Columns to show in comparison\n",
    "\n",
    "class GenericTableComparer:\n",
    "    \"\"\"Generic tool to compare data across groups in any table.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path: Path):\n",
    "        \"\"\"Initialize with database connection.\"\"\"\n",
    "        self.db_path = db_path\n",
    "        self.conn = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Connect to database.\"\"\"\n",
    "        self.conn = sqlite3.connect(str(self.db_path))\n",
    "\n",
    "    def disconnect(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            self.conn = None\n",
    "\n",
    "    def discover_tables(self) -> List[str]:\n",
    "        \"\"\"Discover all tables in database.\"\"\"\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "\n",
    "        query = \"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\"\n",
    "        tables = pd.read_sql_query(query, self.conn)\n",
    "        return tables['name'].tolist()\n",
    "\n",
    "    def analyze_table_structure(self, table_name: str) -> Dict:\n",
    "        \"\"\"Analyze table structure to suggest comparison configuration.\"\"\"\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "\n",
    "        # Get column info\n",
    "        query = f'PRAGMA table_info(\"{table_name}\")'\n",
    "        columns_df = pd.read_sql_query(query, self.conn)\n",
    "\n",
    "        # Get sample data\n",
    "        sample_query = f'SELECT * FROM \"{table_name}\" LIMIT 5'\n",
    "        sample_df = pd.read_sql_query(sample_query, self.conn)\n",
    "\n",
    "        # Identify potential key columns\n",
    "        id_columns = [col for col in columns_df['name'] if 'id' in col.lower()]\n",
    "        pk_column = columns_df[columns_df['pk'] == 1]['name'].tolist()\n",
    "\n",
    "        # Identify potential grouping columns\n",
    "        grouping_candidates = []\n",
    "        for col in sample_df.columns:\n",
    "            if sample_df[col].dtype == 'object':\n",
    "                unique_count = sample_df[col].nunique()\n",
    "                if 2 <= unique_count <= 10:  # Reasonable grouping column\n",
    "                    grouping_candidates.append(col)\n",
    "\n",
    "        return {\n",
    "            'table_name': table_name,\n",
    "            'row_count': len(sample_df),\n",
    "            'columns': columns_df['name'].tolist(),\n",
    "            'primary_keys': pk_column if pk_column else id_columns,\n",
    "            'grouping_candidates': grouping_candidates,\n",
    "            'all_columns_info': columns_df.to_dict('records')\n",
    "        }\n",
    "\n",
    "    def compare_groups(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        grouping_column: str,\n",
    "        comparison_columns: Optional[List[str]] = None,\n",
    "        primary_key: Optional[str] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare data between groups in a table.\n",
    "\n",
    "        Args:\n",
    "            table_name: Name of table to compare\n",
    "            grouping_column: Column to group by (e.g., DOMAIN_CODE)\n",
    "            comparison_columns: Columns to compare (None = all columns)\n",
    "            primary_key: Column to use as identifier\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with comparison results\n",
    "        \"\"\"\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "\n",
    "        # Load data\n",
    "        df = pd.read_sql_query(f'SELECT * FROM \"{table_name}\"', self.conn)\n",
    "\n",
    "        if grouping_column not in df.columns:\n",
    "            raise ValueError(f\"Grouping column '{grouping_column}' not found in table\")\n",
    "\n",
    "        # Identify primary key if not specified\n",
    "        if not primary_key:\n",
    "            id_cols = [col for col in df.columns if 'id' in col.lower() or col == 'ACTION_CODE']\n",
    "            primary_key = id_cols[0] if id_cols else df.columns[0]\n",
    "\n",
    "        # Get unique groups\n",
    "        groups = df[grouping_column].unique()\n",
    "\n",
    "        # Compare each pair of groups\n",
    "        comparisons = {}\n",
    "        for i, g1 in enumerate(groups):\n",
    "            for g2 in groups[i+1:]:\n",
    "                comp_result = self._compare_two_groups(\n",
    "                    df, g1, g2, grouping_column, primary_key, comparison_columns\n",
    "                )\n",
    "                comparisons[f\"{g1}_vs_{g2}\"] = comp_result\n",
    "\n",
    "        return {\n",
    "            'table': table_name,\n",
    "            'grouping_column': grouping_column,\n",
    "            'groups': list(groups),\n",
    "            'group_counts': df.groupby(grouping_column).size().to_dict(),\n",
    "            'comparisons': comparisons\n",
    "        }\n",
    "\n",
    "    def _compare_two_groups(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        group1: str,\n",
    "        group2: str,\n",
    "        grouping_column: str,\n",
    "        primary_key: str,\n",
    "        comparison_columns: Optional[List[str]]\n",
    "    ) -> Dict:\n",
    "        \"\"\"Compare two specific groups.\"\"\"\n",
    "        df1 = df[df[grouping_column] == group1]\n",
    "        df2 = df[df[grouping_column] == group2]\n",
    "\n",
    "        ids1 = set(df1[primary_key].unique())\n",
    "        ids2 = set(df2[primary_key].unique())\n",
    "\n",
    "        common = ids1 & ids2\n",
    "        only_in_1 = ids1 - ids2\n",
    "        only_in_2 = ids2 - ids1\n",
    "\n",
    "        # Compare values for common records\n",
    "        differences = []\n",
    "        if comparison_columns is None:\n",
    "            comparison_columns = [col for col in df.columns\n",
    "                                 if col not in [grouping_column, primary_key]]\n",
    "\n",
    "        for pk_value in common:\n",
    "            row1 = df1[df1[primary_key] == pk_value].iloc[0]\n",
    "            row2 = df2[df2[primary_key] == pk_value].iloc[0]\n",
    "\n",
    "            diffs = {}\n",
    "            for col in comparison_columns:\n",
    "                if col in df.columns:\n",
    "                    val1 = row1[col]\n",
    "                    val2 = row2[col]\n",
    "                    if pd.notna(val1) and pd.notna(val2) and val1 != val2:\n",
    "                        diffs[col] = {'group1': val1, 'group2': val2}\n",
    "\n",
    "            if diffs:\n",
    "                differences.append({\n",
    "                    primary_key: pk_value,\n",
    "                    'differences': diffs\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            'group1': group1,\n",
    "            'group2': group2,\n",
    "            'common_count': len(common),\n",
    "            'only_in_group1_count': len(only_in_1),\n",
    "            'only_in_group2_count': len(only_in_2),\n",
    "            'common_ids': sorted(common),\n",
    "            'only_in_group1': sorted(only_in_1),\n",
    "            'only_in_group2': sorted(only_in_2),\n",
    "            'differences': differences,\n",
    "            'differences_count': len(differences)\n",
    "        }\n",
    "\n",
    "print(\"Generic table comparer loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854c3c2",
   "metadata": {},
   "source": [
    "### Example 1: Discover and Analyze Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639065ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize comparer\n",
    "comparer = GenericTableComparer(DB_PATH)\n",
    "comparer.connect()\n",
    "\n",
    "# Discover all tables\n",
    "tables = comparer.discover_tables()\n",
    "print(\"Available tables:\")\n",
    "for table in tables:\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Analyze structure of key tables\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE STRUCTURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for table in ['MPM_CONFIG', 'COMMUNITIES', 'ACTIONS']:\n",
    "    if table in tables:\n",
    "        print(f\"\\n{table}:\")\n",
    "        analysis = comparer.analyze_table_structure(table)\n",
    "        print(f\"  Rows: {analysis['row_count']}\")\n",
    "        print(f\"  Columns: {len(analysis['columns'])}\")\n",
    "        print(f\"  Primary Keys: {analysis['primary_keys']}\")\n",
    "        print(f\"  Grouping Candidates: {analysis['grouping_candidates']}\")\n",
    "        print(f\"  All Columns: {', '.join(analysis['columns'][:10])}\")\n",
    "        if len(analysis['columns']) > 10:\n",
    "            print(f\"              ... and {len(analysis['columns']) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7996a",
   "metadata": {},
   "source": [
    "### Example 2: Compare Old MPM Tables (mpm_report_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37716c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the old MPM tables if they exist\n",
    "if 'mpm_report_actions' in tables:\n",
    "    print(\"Comparing mpm_report_actions by DOMAIN_CODE:\\n\")\n",
    "\n",
    "    comparison = comparer.compare_groups(\n",
    "        table_name='mpm_report_actions',\n",
    "        grouping_column='DOMAIN_CODE',\n",
    "        comparison_columns=['REPORT_NAME', 'SCHEDULE', 'ACTION_TYPE'],\n",
    "        primary_key='ACTION_CODE'\n",
    "    )\n",
    "\n",
    "    print(f\"Groups found: {comparison['groups']}\")\n",
    "    print(f\"\\nGroup sizes:\")\n",
    "    for group, count in comparison['group_counts'].items():\n",
    "        print(f\"  {group}: {count} records\")\n",
    "\n",
    "    # Show comparison for one pair\n",
    "    if comparison['comparisons']:\n",
    "        first_comp_key = list(comparison['comparisons'].keys())[0]\n",
    "        comp_result = comparison['comparisons'][first_comp_key]\n",
    "\n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(f\"Comparison: {comp_result['group1']} vs {comp_result['group2']}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"Common records: {comp_result['common_count']}\")\n",
    "        print(f\"Only in {comp_result['group1']}: {comp_result['only_in_group1_count']}\")\n",
    "        print(f\"Only in {comp_result['group2']}: {comp_result['only_in_group2_count']}\")\n",
    "        print(f\"Records with differences: {comp_result['differences_count']}\")\n",
    "\n",
    "        if comp_result['differences']:\n",
    "            print(f\"\\nSample differences (first 3):\")\n",
    "            for diff in comp_result['differences'][:3]:\n",
    "                print(f\"\\n  {diff['ACTION_CODE']}:\")\n",
    "                for col, vals in diff['differences'].items():\n",
    "                    print(f\"    {col}:\")\n",
    "                    print(f\"      {comp_result['group1']}: {vals['group1']}\")\n",
    "                    print(f\"      {comp_result['group2']}: {vals['group2']}\")\n",
    "else:\n",
    "    print(\"mpm_report_actions table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65596fea",
   "metadata": {},
   "source": [
    "### Example 3: Compare New YAML Shredder Tables (ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61dd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare YAML Shredder output tables\n",
    "# Note: These tables don't have a grouping column by design - they're from a single file\n",
    "# But we can still analyze their structure\n",
    "\n",
    "if 'ACTIONS' in tables:\n",
    "    print(\"Analyzing ACTIONS table (YAML Shredder output):\\n\")\n",
    "\n",
    "    analysis = comparer.analyze_table_structure('ACTIONS')\n",
    "\n",
    "    print(f\"Table: ACTIONS\")\n",
    "    print(f\"  Columns: {len(analysis['columns'])}\")\n",
    "    print(f\"  Sample columns: {', '.join(analysis['columns'][:15])}\")\n",
    "    if len(analysis['columns']) > 15:\n",
    "        print(f\"  ... and {len(analysis['columns']) - 15} more\")\n",
    "\n",
    "    # Load data to show summary\n",
    "    actions_df = pd.read_sql_query('SELECT * FROM ACTIONS', comparer.conn)\n",
    "\n",
    "    print(f\"\\nData summary:\")\n",
    "    print(f\"  Total actions: {len(actions_df)}\")\n",
    "\n",
    "    # Show action types distribution\n",
    "    if 'action_type' in actions_df.columns:\n",
    "        print(f\"\\nAction types:\")\n",
    "        print(actions_df['action_type'].value_counts().to_string())\n",
    "\n",
    "    # Show sample records\n",
    "    print(f\"\\nSample actions (first 3):\")\n",
    "    display_cols = ['action_code', 'action_type', 'abbreviation']\n",
    "    available_cols = [col for col in display_cols if col in actions_df.columns]\n",
    "    if available_cols:\n",
    "        print(actions_df[available_cols].head(3).to_string(index=False))\n",
    "\n",
    "    print(\"\\n💡 Note: ACTIONS table is from a single YAML file.\")\n",
    "    print(\"   To compare across domains, load multiple YAML files with:\")\n",
    "    print(\"   uv run python yaml_shredder_cli.py all <file> -db <db> -r <domain>_CONFIG\")\n",
    "else:\n",
    "    print(\"ACTIONS table not found. Run YAML shredder first:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7625a2",
   "metadata": {},
   "source": [
    "### Example 4: Batch Comparison Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a825ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comparison report for all relevant tables\n",
    "def generate_comparison_report(\n",
    "    comparer: GenericTableComparer,\n",
    "    tables_to_compare: List[Dict[str, str]]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate comparison report for multiple tables.\n",
    "\n",
    "    Args:\n",
    "        comparer: GenericTableComparer instance\n",
    "        tables_to_compare: List of dicts with 'table', 'grouping_column', 'primary_key'\n",
    "\n",
    "    Returns:\n",
    "        Summary DataFrame\n",
    "    \"\"\"\n",
    "    report = []\n",
    "\n",
    "    for config in tables_to_compare:\n",
    "        table = config['table']\n",
    "\n",
    "        # Check if table exists\n",
    "        all_tables = comparer.discover_tables()\n",
    "        if table not in all_tables:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            comparison = comparer.compare_groups(\n",
    "                table_name=table,\n",
    "                grouping_column=config['grouping_column'],\n",
    "                primary_key=config.get('primary_key')\n",
    "            )\n",
    "\n",
    "            for comp_key, comp_result in comparison['comparisons'].items():\n",
    "                report.append({\n",
    "                    'TABLE': table,\n",
    "                    'COMPARISON': comp_key,\n",
    "                    'GROUP_1': comp_result['group1'],\n",
    "                    'GROUP_2': comp_result['group2'],\n",
    "                    'COMMON': comp_result['common_count'],\n",
    "                    'ONLY_IN_1': comp_result['only_in_group1_count'],\n",
    "                    'ONLY_IN_2': comp_result['only_in_group2_count'],\n",
    "                    'DIFFERENCES': comp_result['differences_count'],\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error comparing {table}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(report)\n",
    "\n",
    "# Configure tables to compare\n",
    "tables_config = [\n",
    "    {'table': 'mpm_deployments', 'grouping_column': 'DOMAIN_CODE', 'primary_key': 'DEPLOYMENT_CODE'},\n",
    "    {'table': 'mpm_communities', 'grouping_column': 'DOMAIN_CODE', 'primary_key': 'COMMUNITY_ID'},\n",
    "    {'table': 'mpm_sensor_actions', 'grouping_column': 'DOMAIN_CODE', 'primary_key': 'ACTION_CODE'},\n",
    "    {'table': 'mpm_report_actions', 'grouping_column': 'DOMAIN_CODE', 'primary_key': 'ACTION_CODE'},\n",
    "]\n",
    "\n",
    "# Generate report\n",
    "print(\"Generating comparison report...\\n\")\n",
    "report_df = generate_comparison_report(comparer, tables_config)\n",
    "\n",
    "if len(report_df) > 0:\n",
    "    print(\"COMPARISON REPORT:\")\n",
    "    print(\"=\"*100)\n",
    "    print(report_df.to_string(index=False))\n",
    "\n",
    "    # Save to CSV\n",
    "    report_path = BASE_DIR / \"table_comparison_report.csv\"\n",
    "    report_df.to_csv(report_path, index=False)\n",
    "    print(f\"\\n✓ Report saved to: {report_path}\")\n",
    "else:\n",
    "    print(\"No comparisons generated. Check if tables exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1522d7",
   "metadata": {},
   "source": [
    "### Example 5: Export Detailed Comparison to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export detailed comparison with differences\n",
    "def export_detailed_comparison(\n",
    "    comparer: GenericTableComparer,\n",
    "    table_name: str,\n",
    "    grouping_column: str,\n",
    "    output_dir: Path,\n",
    "    primary_key: Optional[str] = None\n",
    "):\n",
    "    \"\"\"Export detailed comparison results to CSV files.\"\"\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    comparison = comparer.compare_groups(\n",
    "        table_name=table_name,\n",
    "        grouping_column=grouping_column,\n",
    "        primary_key=primary_key\n",
    "    )\n",
    "\n",
    "    # Export summary\n",
    "    summary_data = []\n",
    "    for comp_key, comp_result in comparison['comparisons'].items():\n",
    "        summary_data.append({\n",
    "            'Comparison': comp_key,\n",
    "            'Group 1': comp_result['group1'],\n",
    "            'Group 2': comp_result['group2'],\n",
    "            'Common Records': comp_result['common_count'],\n",
    "            f\"Only in {comp_result['group1']}\": comp_result['only_in_group1_count'],\n",
    "            f\"Only in {comp_result['group2']}\": comp_result['only_in_group2_count'],\n",
    "            'Records with Differences': comp_result['differences_count'],\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_path = output_dir / f\"{table_name}_comparison_summary.csv\"\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"✓ Summary saved: {summary_path}\")\n",
    "\n",
    "    # Export detailed differences for each comparison\n",
    "    for comp_key, comp_result in comparison['comparisons'].items():\n",
    "        if comp_result['differences']:\n",
    "            diff_data = []\n",
    "            for diff in comp_result['differences']:\n",
    "                row = {primary_key or 'ID': diff[primary_key or list(diff.keys())[0]]}\n",
    "                for col, vals in diff['differences'].items():\n",
    "                    row[f\"{col}_{comp_result['group1']}\"] = vals['group1']\n",
    "                    row[f\"{col}_{comp_result['group2']}\"] = vals['group2']\n",
    "                diff_data.append(row)\n",
    "\n",
    "            diff_df = pd.DataFrame(diff_data)\n",
    "            diff_path = output_dir / f\"{table_name}_{comp_key}_differences.csv\"\n",
    "            diff_df.to_csv(diff_path, index=False)\n",
    "            print(f\"✓ Differences saved: {diff_path}\")\n",
    "\n",
    "# Export comparisons\n",
    "if 'mpm_report_actions' in comparer.discover_tables():\n",
    "    output_dir = BASE_DIR / \"comparison_exports\"\n",
    "\n",
    "    print(\"Exporting detailed comparisons...\\n\")\n",
    "    export_detailed_comparison(\n",
    "        comparer,\n",
    "        table_name='mpm_report_actions',\n",
    "        grouping_column='DOMAIN_CODE',\n",
    "        output_dir=output_dir,\n",
    "        primary_key='ACTION_CODE'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ All exports saved to: {output_dir}\")\n",
    "\n",
    "# Cleanup\n",
    "comparer.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schema-sentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
