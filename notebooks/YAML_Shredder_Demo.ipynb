{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# YAML Shredder & Comparator Demo\n",
    "\n",
    "A comprehensive guide to using Schema Sentinel's powerful tools for transforming YAML/JSON data into relational structures and comparing configurations.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates:\n",
    "- **YAML Shredder**: Convert nested YAML/JSON files into normalized relational tables\n",
    "- **YAML Comparator**: Compare two YAML files to identify structural and data differences\n",
    "- **Document Generator**: Generate markdown documentation from YAML configurations\n",
    "- **SQL DDL Generation**: Create database schemas for the Snowflake SQL dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Installation\n",
    "\n",
    "First, let's ensure the yaml_shredder package is properly installed and ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Verify yaml_shredder is available\n",
    "try:\n",
    "    import yaml_shredder\n",
    "    print(f\"âœ“ yaml_shredder version: {yaml_shredder.__version__}\")\n",
    "    print(f\"âœ“ Location: {yaml_shredder.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Error importing yaml_shredder: {e}\")\n",
    "    raise RuntimeError(\"yaml_shredder is required for this demo notebook. Please install it (e.g., 'pip install yaml_shredder') and retry.\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Section 2: Import Required Modules\n",
    "\n",
    "Import all the necessary modules from yaml_shredder for YAML processing and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import tempfile\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from yaml_shredder import (\n",
    "    TableGenerator,\n",
    "    DDLGenerator,\n",
    "    StructureAnalyzer,\n",
    "    SQLiteLoader,\n",
    "    YAMLComparator,\n",
    "    generate_doc_from_yaml,\n",
    ")\n",
    "\n",
    "# Set up temporary directory for this demo with unique suffix to avoid conflicts\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "TEMP_DIR = Path(tempfile.gettempdir()) / f\"yaml_shredder_demo_{timestamp}\"\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Working directory: {TEMP_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Section 3: Create Sample YAML Files\n",
    "\n",
    "Let's create sample YAML files to demonstrate the yaml_shredder and comparator functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample YAML file 1 (Original configuration)\n",
    "config_v1 = {\n",
    "    \"deployment\": {\n",
    "        \"environment\": \"production\",\n",
    "        \"region\": \"us-east-1\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    },\n",
    "    \"database\": {\n",
    "        \"host\": \"db.example.com\",\n",
    "        \"port\": 5432,\n",
    "        \"name\": \"main_db\"\n",
    "    },\n",
    "    \"services\": [\n",
    "        {\n",
    "            \"name\": \"api-service\",\n",
    "            \"port\": 8080,\n",
    "            \"replicas\": 3,\n",
    "            \"cpu\": \"500m\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"cache-service\",\n",
    "            \"port\": 6379,\n",
    "            \"replicas\": 2,\n",
    "            \"cpu\": \"250m\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "yaml_file_1 = TEMP_DIR / \"config_v1.yaml\"\n",
    "with open(yaml_file_1, \"w\") as f:\n",
    "    yaml.safe_dump(config_v1, f)\n",
    "\n",
    "print(f\"âœ“ Created {yaml_file_1.name}\")\n",
    "print(\"\\nContent of config_v1.yaml:\")\n",
    "pprint(config_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample YAML file 2 (Updated configuration with changes)\n",
    "config_v2 = {\n",
    "    \"deployment\": {\n",
    "        \"environment\": \"production\",\n",
    "        \"region\": \"us-west-2\",  # Changed\n",
    "        \"version\": \"1.1.0\"      # Changed\n",
    "    },\n",
    "    \"database\": {\n",
    "        \"host\": \"db-new.example.com\",  # Changed\n",
    "        \"port\": 5432,\n",
    "        \"name\": \"main_db\",\n",
    "        \"ssl_enabled\": True  # New\n",
    "    },\n",
    "    \"services\": [\n",
    "        {\n",
    "            \"name\": \"api-service\",\n",
    "            \"port\": 8080,\n",
    "            \"replicas\": 5,      # Changed\n",
    "            \"cpu\": \"500m\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"cache-service\",\n",
    "            \"port\": 6379,\n",
    "            \"replicas\": 2,\n",
    "            \"cpu\": \"250m\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"worker-service\",  # New service\n",
    "            \"port\": 9000,\n",
    "            \"replicas\": 1,\n",
    "            \"cpu\": \"100m\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "yaml_file_2 = TEMP_DIR / \"config_v2.yaml\"\n",
    "with open(yaml_file_2, \"w\") as f:\n",
    "    yaml.safe_dump(config_v2, f)\n",
    "\n",
    "print(f\"âœ“ Created {yaml_file_2.name}\")\n",
    "print(\"\\nContent of config_v2.yaml:\")\n",
    "pprint(config_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Section 4: Analyze YAML Structure\n",
    "\n",
    "First, let's analyze the structure of our YAML files to understand what nested elements they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the structure\n",
    "with open(yaml_file_1) as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "analyzer = StructureAnalyzer(max_depth=3)\n",
    "analysis = analyzer.analyze(data)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"YAML STRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "analyzer.print_summary(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Section 5: Convert YAML to Relational Tables\n",
    "\n",
    "Transform the nested YAML structure into normalized relational tables for database storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tables from YAML\n",
    "table_gen = TableGenerator(max_depth=None)  # Full flattening\n",
    "tables = table_gen.generate_tables(data, root_table_name=\"CONFIG\", source_file=yaml_file_1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GENERATED TABLES\")\n",
    "print(\"=\" * 70)\n",
    "table_gen.print_summary()\n",
    "\n",
    "print(\"\\nTable Details:\")\n",
    "for table_name, df in tables.items():\n",
    "    print(f\"\\nðŸ“Š Table: {table_name}\")\n",
    "    print(f\"   Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "    print(f\"   Schema: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample data from SERVICES table\n",
    "if \"SERVICES\" in tables:\n",
    "    print(\"\\nSample SERVICES data:\")\n",
    "    print(tables[\"SERVICES\"].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Section 6: Load Tables into SQLite Database\n",
    "\n",
    "Store the generated tables in a SQLite database for persistence and querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables into SQLite\n",
    "db_path = TEMP_DIR / \"config.db\"\n",
    "loader = SQLiteLoader(db_path)\n",
    "loader.connect()\n",
    "loader.load_tables(tables, if_exists=\"replace\", create_indexes=True)\n",
    "loader.print_summary()\n",
    "loader.disconnect()\n",
    "\n",
    "print(f\"\\nâœ“ Database created at: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Section 7: Generate SQL DDL\n",
    "\n",
    "Create SQL DDL statements for multiple database systems to recreate the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DDL for Snowflake\n",
    "ddl_gen = DDLGenerator(dialect=\"snowflake\")\n",
    "ddl_statements = ddl_gen.generate_ddl(tables, table_gen.relationships)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SQL DDL - SNOWFLAKE DIALECT\")\n",
    "print(\"=\" * 70)\n",
    "for table_name, sql in ddl_statements.items():\n",
    "    print(f\"\\n-- Table: {table_name}\")\n",
    "    print(sql)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Section 8: Compare Two YAML Files\n",
    "\n",
    "Use YAMLComparator to identify differences between the two configuration versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize comparator\n",
    "comparator = YAMLComparator(output_dir=TEMP_DIR / \"comparisons\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"YAML COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load YAML files to databases for comparison\n",
    "db1 = comparator.load_yaml_to_db(yaml_file_1, max_depth=None)\n",
    "db2 = comparator.load_yaml_to_db(yaml_file_2, max_depth=None)\n",
    "\n",
    "print(f\"\\nâœ“ Loaded {yaml_file_1.name} â†’ {db1.name}\")\n",
    "print(f\"âœ“ Loaded {yaml_file_2.name} â†’ {db2.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table information for both databases\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Table Information Comparison\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "tables_db1 = comparator.get_table_info(db1)\n",
    "tables_db2 = comparator.get_table_info(db2)\n",
    "\n",
    "print(f\"\\nDatabase 1 ({yaml_file_1.name}):\")\n",
    "for table_name in tables_db1.keys():\n",
    "    print(f\"  - {table_name}\")\n",
    "\n",
    "print(f\"\\nDatabase 2 ({yaml_file_2.name}):\")\n",
    "for table_name in tables_db2.keys():\n",
    "    print(f\"  - {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row counts to identify changes\n",
    "row_counts_db1 = comparator.get_row_counts(db1)\n",
    "row_counts_db2 = comparator.get_row_counts(db2)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Row Count Comparison\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "all_tables = set(row_counts_db1.keys()) | set(row_counts_db2.keys())\n",
    "for table in sorted(all_tables):\n",
    "    count1 = row_counts_db1.get(table, 0)\n",
    "    count2 = row_counts_db2.get(table, 0)\n",
    "    change = count2 - count1\n",
    "    symbol = \"+\" if change > 0 else \"-\" if change < 0 else \"=\"\n",
    "    print(f\"{table:20} {count1:3d} â†’ {count2:3d} [{symbol}{abs(change)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Section 9: Generate Comparison Report\n",
    "\n",
    "Create a detailed markdown report showing the differences between the two YAML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed comparison report\n",
    "report_path = TEMP_DIR / \"comparison_report.md\"\n",
    "\n",
    "report = comparator.compare_yaml_files(\n",
    "    yaml1_path=yaml_file_1,\n",
    "    yaml2_path=yaml_file_2,\n",
    "    output_report=report_path,\n",
    "    keep_dbs=True,\n",
    "    root_table_name=\"CONFIG\"\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Comparison report saved to: {report_path}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARISON REPORT (Preview)\")\n",
    "print(\"=\" * 70)\n",
    "print(report[:1500] + \"...\\n[Report truncated for display]\")\n",
    "\n",
    "# Also display the raw report content\n",
    "print(\"\\nFull report path:\", report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Section 10: Generate Markdown Documentation\n",
    "\n",
    "Create comprehensive markdown documentation from the YAML configuration showing all tables and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown documentation\n",
    "docs_dir = TEMP_DIR / \"docs\"\n",
    "docs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "doc_path = generate_doc_from_yaml(\n",
    "    yaml_path=yaml_file_1,\n",
    "    output_dir=docs_dir,\n",
    "    root_name=\"CONFIG\",\n",
    "    max_depth=None,  # Full flattening\n",
    "    keep_db=False    # Remove temporary database\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Documentation generated: {doc_path}\")\n",
    "print(f\"  File size: {doc_path.stat().st_size:,} bytes\")\n",
    "\n",
    "# Show preview of the documentation\n",
    "with open(doc_path) as f:\n",
    "    doc_content = f.read()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DOCUMENTATION PREVIEW\")\n",
    "print(\"=\" * 70)\n",
    "print(doc_content[:1000] + \"...\\n[Documentation truncated for display]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Section 11: Summary and Key Takeaways\n",
    "\n",
    "Review the key features and use cases of YAML Shredder and Comparator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY - YAML SHREDDER & COMPARATOR CAPABILITIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = \"\"\"\n",
    "âœ“ YAML SHREDDER FEATURES:\n",
    "  1. Structure Analysis - Identify nested structures and data patterns\n",
    "  2. Table Generation - Convert nested YAML/JSON into normalized tables\n",
    "  3. Database Loading - Store transformed data in SQLite with indexes\n",
    "  4. DDL Generation - Create SQL schemas for Snowflake, PostgreSQL, MySQL\n",
    "  5. Depth Control - max_depth parameter controls flattening levels\n",
    "\n",
    "âœ“ YAML COMPARATOR FEATURES:\n",
    "  1. Database Loading - Convert YAML files to SQLite databases\n",
    "  2. Schema Comparison - Identify table and column differences\n",
    "  3. Row Count Analysis - Track data changes between versions\n",
    "  4. Difference Detection - Automatically detect added/removed/modified rows\n",
    "  5. Report Generation - Create detailed markdown comparison reports\n",
    "\n",
    "âœ“ DOCUMENTATION GENERATOR FEATURES:\n",
    "  1. Markdown Output - Generate comprehensive documentation\n",
    "  2. Schema Details - Show table schemas with column types\n",
    "  3. Data Preview - Display actual table data in markdown tables\n",
    "  4. Smart Truncation - Preserve JSON objects, truncate regular text\n",
    "  5. File Naming - Auto-name documents after source files\n",
    "\n",
    "USE CASES:\n",
    "  â€¢ Configuration Drift Detection - Compare YAML across environments\n",
    "  â€¢ Data Pipeline Transformation - Normalize nested data for analytics\n",
    "  â€¢ Schema Discovery - Infer database schemas from YAML examples\n",
    "  â€¢ Change Tracking - Monitor configuration evolution over time\n",
    "  â€¢ API Response Processing - Convert JSON API responses to tables\n",
    "  â€¢ Environment Synchronization - Ensure config consistency\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FILES GENERATED IN THIS DEMO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Working Directory: {TEMP_DIR}\")\n",
    "for item in sorted(TEMP_DIR.rglob(\"*\")):\n",
    "    if item.is_file():\n",
    "        rel_path = item.relative_to(TEMP_DIR)\n",
    "        size = item.stat().st_size\n",
    "        print(f\"  {rel_path} ({size:,} bytes)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
